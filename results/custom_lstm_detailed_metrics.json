{
  "model_name": "Custom LSTM+Attention",
  "architecture": {
    "vocab_size": 474,
    "embedding_dim": 256,
    "hidden_dim": 128,
    "num_layers": 2,
    "dropout": 0.3
  },
  "metrics": {
    "accuracy": 1.0,
    "precision": 1.0,
    "recall": 1.0,
    "f1_score": 1.0,
    "roc_auc": 1.0,
    "specificity": 1.0
  },
  "confusion_matrix": {
    "true_negatives": 472,
    "false_positives": 0,
    "false_negatives": 0,
    "true_positives": 471
  },
  "test_set_size": 943,
  "training_params": {
    "test_size": 0.2,
    "random_state": 42,
    "max_sequence_length": 100
  }
}